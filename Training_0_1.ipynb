{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "The tensorboard.notebook extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard.notebook\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#import model\n",
    "#import training\n",
    "import loaders\n",
    "import game_print\n",
    "\n",
    "import sys\n",
    "from demoparser.demofile import DemoFile\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib qt\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "#Check to make sure my GPU is running/is been used\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading game 0\n",
      "Round  0\n",
      "Round  1\n",
      "Round  2\n",
      "Round  3\n",
      "Round  4\n",
      "Round  5\n",
      "Round  6\n",
      "Round  7\n",
      "Round  8\n",
      "Round  9\n",
      "Round  10\n",
      "Round  11\n",
      "Round  12\n",
      "Round  13\n",
      "Round  14\n",
      "Round  15\n",
      "Round  16\n",
      "Round  17\n",
      "Round  18\n",
      "Round  19\n",
      "Round  20\n",
      "Round  21\n",
      "Round  22\n",
      "Round  23\n",
      "Round  24\n",
      "Round  25\n",
      "Finished loading game!\n"
     ]
    }
   ],
   "source": [
    "#Import Game data into games list\n",
    "games = loaders.import_games_by_directory(\"test_CSGO_DEM_FILES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_print.AnimateRound(games[0].m_rounds[1],'newdeadtest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "batch_size = 16\n",
    "network_z, network_x, network_y = 10, 128, 128\n",
    "blob_size = 2.5\n",
    "\n",
    "def get_batches():\n",
    "    #This is'nt an efficent way of flattening list lists, but it does look cool\n",
    "    rounds = sum([g.m_rounds for g in games],[])\n",
    "    \n",
    "    #Currently just stick all rounds indiscriminitely together\n",
    "    for r in rounds:\n",
    "        l = max([len(p.states) for p in r.players])\n",
    "        print(\"Generating batches from round\", r.m_rid, \"length\", l)\n",
    "\n",
    "        for b_ix in range(l//batch_size):  # Ignore bits at end that don't make up a whole batch\n",
    "            #print(\"Batch\", b_ix)\n",
    "            Y = np.zeros((batch_size, network_z, network_x, network_y))\n",
    "\n",
    "            # Generate batch\n",
    "            for f in range(batch_size):\n",
    "                i = b_ix*batch_size + f  # index of frame in round\n",
    "\n",
    "                # Draw blob for each player\n",
    "                for p_ix, p in enumerate(r.players):\n",
    "                    (pos, vis, dead) = p.states[i]\n",
    "                    if not dead:\n",
    "                        put_heatmap(Y[f, p_ix], pos)\n",
    "            \n",
    "            # Grab state data for each player\n",
    "            states = []\n",
    "            for p_ix, p in enumerate(r.players):\n",
    "                states.append(p.states[b_ix*batch_size : (b_ix+1)*batch_size])\n",
    "\n",
    "            # Reorder axis for input to network (ix,z,x,y) -> (ix,x,y,z)\n",
    "            Y = np.moveaxis(Y, 1, -1)\n",
    "            yield Y, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of frame# Put a blob in the required place of a 2d matrix\n",
    "# Can do this way faster, but it's fine for now..\n",
    "def put_heatmap(heatmap, center):\n",
    "    center_x, center_y = center\n",
    "    \n",
    "    # Rescale ..\n",
    "    x1, x2, y1, y2 = (-2600., 2100., -1200., 3200.)\n",
    "\n",
    "    center_x = (center_x - x1) / (x2 - x1) * network_x\n",
    "    center_y = (center_y - y1) / (y2 - y1) * network_y\n",
    "    \n",
    "    height, width = heatmap.shape\n",
    "\n",
    "    th = 4.6052\n",
    "    \n",
    "    delta = math.sqrt(th * 2)\n",
    "\n",
    "    # Vectorize\n",
    "    sigma = blob_size\n",
    "    x0 = int(max(0, center_x - delta * sigma))\n",
    "    y0 = int(max(0, center_y - delta * sigma))\n",
    "\n",
    "    x1 = int(min(width - 1, center_x + delta * sigma))\n",
    "    y1 = int(min(height - 1, center_y + delta * sigma))\n",
    "\n",
    "    exp_factor = 1 / 2.0 / sigma / sigma\n",
    "    arr_heatmap = heatmap[y0:y1 + 1, x0:x1 + 1] # Not nessasary unless we have > 1 blob per input\n",
    "    y_vec = (np.arange(y0, y1 + 1) - center_y) ** 2  # y1 included\n",
    "    x_vec = (np.arange(x0, x1 + 1) - center_x) ** 2\n",
    "    xv, yv = np.meshgrid(x_vec, y_vec)\n",
    "    arr_sum = exp_factor * (xv + yv)\n",
    "    arr_exp = np.exp(-arr_sum)\n",
    "    arr_exp[arr_sum > th] = 0\n",
    "    \n",
    "    heatmap[y0:y1 + 1, x0:x1 + 1] = np.maximum(arr_heatmap, arr_exp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do teh learning!\n",
    "\n",
    "from model import unet\n",
    "#pretrained_weights=\"csgo_zero.h5\"\n",
    "model = unet(input_size=(128,128,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "debug = False\n",
    "\n",
    "def train_network():\n",
    "    step = 0\n",
    "    print_param = gamePrinter.print_single_frame(np.ones((160,160,10)));\n",
    "    for e in range(num_epochs):\n",
    "        \n",
    "        btchs = get_batches()\n",
    "        # Just dump first batch pretty much\n",
    "\n",
    "        Y0, _ = next(btchs)\n",
    "\n",
    "        # Initial state is just the very first frame of the game,\n",
    "        # which is known to both sides anyway(!)\n",
    "        # After the first loop, it'll be a prediction of the first frame in the batch.\n",
    "        c_frame = Y0[-1]\n",
    "\n",
    "        # Frame index for input vs output.\n",
    "        # k(ix) = global knowledge from frame ix\n",
    "\n",
    "        # input (X)       | output (Y)\n",
    "        # ----------------------------\n",
    "        # 0               | 1\n",
    "        # pred(0) + k(1)  | 2\n",
    "        # pred(x1) + k(2) | 3\n",
    "        # pred(x2) + k(3) | 4\n",
    "\n",
    "        #while True:\n",
    "        for Y, states in btchs:\n",
    "            # Each loop here creates a new training batch and updates the network based on it.\n",
    "\n",
    "            # Make batch input\n",
    "            X = np.empty((batch_size, network_x, network_y, network_z))\n",
    "\n",
    "            for f_ix in range(batch_size):\n",
    "                # Add current frame to batch (copying)\n",
    "                # This way, X always lags behind Y by one frame.\n",
    "                X[f_ix,:] = c_frame\n",
    "\n",
    "                # Predict next frame (f_ix) based on current one (expanding and reducing dimensions cause stuff)\n",
    "                c_frame = model.predict(np.expand_dims(c_frame, axis=0))[0]\n",
    "\n",
    "                # Update with any knowledge we have. (i.e. player visible or dead)\n",
    "                #ix = starting_frame + f_ix  # current frame index\n",
    "\n",
    "                for p_id in range(network_z):\n",
    "                    _, is_spotted, is_dead = states[p_id][f_ix]\n",
    "                    if p_id < 5 or is_spotted or is_dead:\n",
    "                        # If player is dead or visible, we now know what it's doing...\n",
    "                        # update it's layer to the ground truth. (of what will be effectively the previous frame)\n",
    "                        c_frame[:,:,p_id] = Y[f_ix,:,:,p_id]                \n",
    "            \n",
    "            \n",
    "\n",
    "            # Train model!!! on our newly created X and Y batches (:D)\n",
    "            loss = model.train_on_batch(X, Y)\n",
    "            #import pdb; pdb.set_trace()\n",
    "            print_param = gamePrinter.print_single_frame(c_frame, print_param[0], print_param[1]);\n",
    "            if step % 100 == 0:\n",
    "                print(loss)\n",
    "                \n",
    "            step += 1\n",
    "          \n",
    "        \n",
    "        #import pdb; pdb.set_trace() #check that frame makes sense using print_frame()\n",
    "    #model.save('csgo_{}.h5'.format(e))  # creates a HDF5 file 'my_model.h5'\n",
    "    if e % 3 == 0:\n",
    "        model.save('csgo_zero.h5')\n",
    "\n",
    "train_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/scalars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
